{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72700338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vishesh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing all the required libraries\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba9aaeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word2Vec model\n",
    "location = \"GoogleNews-vectors-negative300.bin\"\n",
    "wv = KeyedVectors.load_word2vec_format(location, binary=True, limit=1000000)\n",
    "wv.save_word2vec_format('vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ab147f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load_word2vec_format('vectors.csv', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cec4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load phrases from CSV\n",
    "phrases_csv_path = \"phrases.csv\"\n",
    "phrases_df = pd.read_csv(phrases_csv_path,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a8085503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the word embeddings for a phrase\n",
    "def get_phrase_embeddings(phrase, model):\n",
    "    tokens = phrase.split()\n",
    "    valid_tokens = [token for token in tokens if token in model.key_to_index]\n",
    "    if not valid_tokens:\n",
    "        return None\n",
    "    # Calculate the normalized sum of word embeddings\n",
    "    phrase_vector = sum(model.get_vector(token) / model.get_vecattr(token, 'count') for token in valid_tokens)\n",
    "    return phrase_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2d129182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign embeddings to each word in each phrase\n",
    "phrases_df['embeddings'] = phrases_df['Phrases'].apply(lambda x: get_phrase_embeddings(x, wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0f5b5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate distances between phrases\n",
    "def calculate_distances(phrases_df, distance_metric='euclidean'):\n",
    "    embeddings = np.stack(phrases_df['embeddings'].dropna().to_numpy())\n",
    "\n",
    "    if distance_metric == 'euclidean':\n",
    "        distances = euclidean_distances(embeddings, embeddings)\n",
    "    elif distance_metric == 'cosine':\n",
    "        distances = cosine_distances(embeddings, embeddings)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid distance metric. Use 'euclidean' or 'cosine'.\")\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2511b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "euclidean_distances_matrix = calculate_distances(phrases_df, distance_metric='euclidean')\n",
    "cosine_distances_matrix = calculate_distances(phrases_df, distance_metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bc84b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_match(user_input, phrases_df, model, distance_metric='euclidean'):\n",
    "    user_input_embedding = get_phrase_embeddings(user_input, model)\n",
    "    if user_input_embedding is None:\n",
    "        return None, None\n",
    "\n",
    "    # Calculate distances and store them in a new 'distance' column\n",
    "    phrases_df['distance'] = phrases_df['embeddings'].apply(\n",
    "        lambda x: euclidean_distances([user_input_embedding], [x]) if distance_metric == 'euclidean'\n",
    "        else cosine_distances([user_input_embedding], [x])\n",
    "    )\n",
    "\n",
    "    # Find the index of the minimum distance using np.argmin\n",
    "    closest_match_index = np.argmin(phrases_df['distance'].apply(lambda x: x[0]).to_numpy())\n",
    "\n",
    "    # Retrieve the closest match and distance\n",
    "    closest_match_phrase = phrases_df.loc[closest_match_index, 'Phrases']\n",
    "    distance_to_closest_match = phrases_df.loc[closest_match_index, 'distance'][0]\n",
    "\n",
    "    return closest_match_phrase, distance_to_closest_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d001f1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the sentence: hello\n",
      "Closest Match: How much money did Lloyd's of London make last year?, Distance: [0.78965292]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_input_phrase = input(\"Please enter the sentence: \")\n",
    "closest_match, distance_to_closest_match = find_closest_match(user_input_phrase, phrases_df, wv, distance_metric='cosine')\n",
    "print(f\"Closest Match: {closest_match}, Distance: {distance_to_closest_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d990d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
